\chapter{Introduction}
\label{chp:introduction}

% What do I want to say and convey here?
% - scientific publications are the ``footprint'' and ``medium of discourse'' of academic progress
% - structured representation

% establish the nature and role of scientific publications
Scientific publications are the \emph{discourse medium} and \emph{literary footprint} of academic progress. As such, they play a vital role in the everyday workings and advancement of academia.
% segue to the digital
Historically, this role manifested itself physically---through ink on paper. In time, digital methods for authoring %/composition?
and distribution enabled more efficient ways of dissemination.
Today, scientific publications are predominantly authored, distributed, consumed, and archived digitally~\cite{Lamers2018}. However, the form of today's digital publications still retains numerous and deep traces of its physical ancestry.

% Digital dissemination makes the transfer of new knowledge into the research community faster and cheaper. Digital archives enable search technology and analytics to operate on our \emph{literary footprint} of past and present academic progress. In this way, digitization facilitates both faster progress in science, \emph{and} technology helping scientists to keep up with the increase in speed. However, today's form of digital publications is far from optimal for powering such technology. In fact, the form of today's digital publications poses significant challenges for 

% While there lies enormous potential in a digital record of science, there remain significant challenges to realizing this potential. A key cause of these challenges is the historical baggage of today's digital publications. This dissertation is in pursuit of tackling these challenges.

% There lies enormous potential in a digital record of science. But realizing this potential

The historical baggage manifesting itself in the PDF files we read, share, and author, poses significant challenges to realizing the full potential of a digital record of science. While digital services in academia such as search and recommendation do exist, they are powered not by publications themselves, but rather by more structured, derivative representations of publications. The same holds for analyses of publications (see Figure~\ref{fig:introduction-structreps}). Creating such structured representations %/derivates?
is challenging and error-prone, leading to a risk of subpar services and erroneous analyses. This dissertation represents an effort to tackle this challenge and alleviate the quality of structured representations of scientific publications.

% (random alliteration: structured surrogates of academic archives)

% - b/c of discrepancy between current form and what would be even better for digital dissemination and use (e.g. more structured), structured derivates of publications that enable digital services are of limited quality
% - historical baggage in part b/c still meant for human consumption
% - gap(?) between “pure” digital form and current form hinders more efficient use in digital services surrounding publications and academia

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/introduction/structured_representations_of_publucations}
  \caption[test]{Visualisation of publications, their structured representations, and their use.}
  \label{fig:introduction-structreps}
\end{figure}

\section{Scope and Motivation}

% What do I want to say and convey here?
% - why do we have/need scholarly data?
% - in contrast to intro paragraphs above, make *necessity* of scholarly data for mitigating information overload clear
% - also make clear why there was realistic potential in approaching the challenge

% Scholarly documents: research papers, project proposals, technical reports and academic documents
% 

% We first lay our the scope of the subject we consider as well as its significance. Based on this, we derive the motivation of the research project.

The focus subject of this dissertation are \textit{structured representations of scientific publications}%
%. For the sake of brevity, we will use the term ``scholarly data'' synonymously %
%\footnote{Note that in other contexts the term ``scholarly data'' can have a broader meaning than just ``structured representations of scientific publications''. For example, it can also include data on research institutions or funding bodies, without necessitating the context of a publication.} 
% and define the concept as follows.
, which we define as follows.

\begin{quote}
\textbf{Structured Representations of Scientific Publications}: Data representing the properties and contents of pieces of scientific literature in a structured way.
\end{quote}

For the sake of brevity, we use the term ``scholarly data'' synonymously.

\begin{quote}
\textbf{Scholarly Data}: Term used synonymously to ``structured representations of scientific publications'' in the context of this dissertation.
\end{quote}

% In other contexts, above terms can have a broader meaning and include, for example, data on research institutions or funding bodies, without necessitating the context of a publication.
% In the broadest sense, a collection of PDF files ... (NOTE: Scholarly data ``defined'' again in ch 2.1)
% Scholarly data, as defined above rooted in
% Being based on scientific literature, scholarly data is both a product
%\footnote{Note that in other contexts the term ``scholarly data'' can have a broader meaning than just ``structured representations of scientific publications''. For example, it can also include data on research institutions or funding bodies, without necessitating the context of a publication.} 

The importance of scholarly data, specifically large-scale scholarly data that is of high quality, lies in its potential as a remedy to challenges brought by the digitization of academic publishing.

% * in the olden days there were polymaths
% * nowadays an expert can't humanly keep up with their field
% * → we need assistance
% * → my research in on enabling the creating of such assistance

% * since ever, humans have sought shortcuts
% * in decision making in science: h-index etc. (not sure if this fits b/c I don't specifically address such metrics)

The digitization of academic publishing has made the transfer of new knowledge into the research community faster, thereby enabling an acceleration of scientific progress. A second driver of acceleration is the increase in research spending across the world~\cite{CRS2022,OECD2023}.
This increase in scientific progress, while first and foremost a positive development, brings with it a growing challenge for researchers to keep up with the literature. This problem is referred to as ``information overload''~\cite{Landhuis2016}.
Fortunately, the digitization of academic publishing not only lead to %/facilitated
an increase in the rate at which research results are being published. It also marks the inception of scholarly data, and thereby enabled search technology and analytics to operate on large collections of digitally archived publications.
In this way, the existence of digital representations of publications also provides, to some degree, a remedy for information overload. Efficient search and recommendation services, for example, can aid researchers in navigating the deluge of publications they're faced with.
Similarly, decision processes in academia, such as the evaluation of institutions or researchers, is enabled by scholarly data through performance indicators. In this way, it provides a means for hiring and funding decisions.
In other words, scholarly data is a vital resource for decision making in academia on the individual as well as organisational level.

The quality of decisions made based on scholarly data, naturally, hinges on the quality of the scholarly data itself. If, for example, citations are missing in the data, this might cause researchers to overlook relevant related work, or a funding body to under-evaluate an institution. Recalling that the creation of scholarly data is a challenging and error-prone process, it stands to reason that efforts to improve scholarly data quality are a worthwhile endeavor. Based on these considerations, the overarching objective pursued in this dissertation is the development of methods for creating high-quality scholarly data.

% * not only is my research addressing the now pressing and increasing issue of an increasing rate of publication
% * it also tackles blind spots the have been left unaddressed for long (x-ling)

\section{Research Objective}\label{sec:intro-researchobj}

% What do I want to say and convey here?
% - make approached problem more concrete
%   - hand-wave-y in above:
%       ``[digital services in academia] are powered not by publications themselves,
%         but rather by more structured, derivative representations of publications''
%     -> publications authored by humans for humans -> scholarly data secondary/derivate
%     => concretization: derive structured representation from publications
%   - ``high-quality''
%     -> briefly touch upon what's laid out in foundation chapter
%     => concretization: high-quality = fitness for use
% - (maybe even narrow down to reference focus, maybe *even* more to LaTeX based)
% - give example

To define our research objective, we need to take a closer look at what ``creating high-quality scholarly data'' entails. As briefly laid out above, scholarly data is a derivative product of publications. This is due to the fact that, for the time being, scientific publications are written by humans for humans. Because the product of this process is not well suited for digital processing \emph{as is}, scholarly data is created as a derivate based on publications. To make this feasible on a large scale, the creation has to be automated.

Accordingly, we can define our research objective as follows.

\begin{infobox-objective}
\textbf{Research Objective}\\
Develop an automated process that takes as input scientific publications, and produces as output a high-quality derivative representation of the publications suitable for digital processing.
\end{infobox-objective}

This leaves the question of what ``high-quality'' and ``suitable for digital processing'' entail. We discuss this aspect in detail in Chapter~\ref{chp:foundations}. In short, data quality depends on the intended use and therefore, very generally speaking, means \emph{fitness for use}. Quantitatively it can be assessed along the following five dimensions~\cite{Herzog2007}.

\begin{infobox-progress}
      \textbf{Data Quality Dimensions}\\
       (1)~relevance, (2)~accuracy, (3)~timeliness, (4)~comparability, (5)~completeness
\end{infobox-progress}

A more specific and concrete definition of scholarly data quality along these dimensions can be grounded in considerations of how scholarly data is used. We elaborate on this in Section~\ref{sec:foundations-dataquality}.

\section{Challenges}\label{sec:intro-challenges}

% What do I want to say and convey here?
% - (TODO: look at foundations part and see if challenges are laid out clearly already)

% big picture view on bridging the gap between historical baggage documents (print, scan, PDF, ...) and digital representation
% - large existing current effort
%       - document image dewarping\refurl{https://github.com/fh2019ustc/Awesome-Document-Image-Rectification}{2023-11-21}
%       - OCR
%       - PDF based scholarly data stuff

% - volume / growth rate (10^6 docs, 10^7 refs)
% - bridging visual medium and text information (formats etc., ref chap 2)
% - human made data (ambiguity, information sparsity)
% - reference open world something something
% - multi-lingual
% - specialized notation
% - 

Developing a process as described above is challenging for several reasons.

\begin{enumerate}
    \item \textbf{Data Volume} The value to be gained from scholarly data often increases with the number of publications covered. As a consequence, data sets are often very large (millions of documents). This leads to challenges in terms of processing efficiency, variability of data, and fault tolerance.
    \item \textbf{Unbounded Domain} A key characteristic of scientific publications is that they contain lots of references to other published works. This leads to the challenge of having to deal with an unbounded domain, because it is practically infeasible for a process as described in the previous section to have access to everything ever published or referenced.
    \item \textbf{Information Sparsity} Because the ``source material'' scholarly data is constructed from (publications) is created with human consumption in mind, various pieces of information necessary for understanding can be left out. This is due to the fact that readers can be assumed to possess relevant background knowledge. Following from this is the challenge of having to fill in background information in order to make scholarly data complete.
    \item \textbf{Semantic Ambiguity} Similar to information sparsity, the fact that the input data to be processed is natural language text, means the natural language processing (NLP) problem of ambiguity comes into play.
    \item \textbf{Multi-Linguality} While English currently is the de facto academic lingua franca~\cite{Montgomery2013}, science is a global endeavor meaning that scientific publications are written in various languages. Accordingly, the creation of scholarly data can entail the challenges that come with processing multi-lingual text.
    \item \textbf{Specialized Content} The fact that scientific publications address highly specialized topics, means that they are likely to contain both specialized terminology, as well as specialized notation. Both of these aspects result in further challenges in processing their natural language contents.
\end{enumerate}

Some of the aspects mentioned above are common for NLP tasks in general, such as semantic ambiguity. However, in their entirety, these challenges set the task apart from other areas, such as approaches concerned with news articles, which contain less specialized language, and websites, where the source material is more structured in nature. Rather close to above challenges is the processing of patents. However, patents also contain legal jargon, which is generally not the case for scientific publications.\footnote{The similarity between scientific publications and patents regarding the nature of their content, purpose, and requirements for automated processing, are likely the reason that some platforms, such as Google Scholar, handle both within a single system. The search interface at \refurlinline{https://scholar.google.com/}{2023-11-22}, for example, includes a filter option ``include patents''.}

% differences to patents: nature of the language technical and legal (as opposed to scientific)

\section{Research Gap}\label{sec:intro-gap}

This dissertation is not the first, and will certainly also not be the last research endeavor with the objective the develop methods for the creation of high-quality scholarly data. To position our work in relation to existing approaches, we below highlight the research gaps addressed by this dissertation. More detailed accounts regarding each area can be found in the respective chapters later on.

\begin{enumerate}
    \item \textbf{Citation Network} Several of the most prevalent use cases for scholarly data hinge on the interlinking of publications through citations. This includes a large amount of bibliometric analyses, scientometrics, as well as the study of citation networks in the general context of graphs (e.g. in graph neural network evaluations). Despite this, not much focus is put on the quality of citation networks in scholarly data. The much used data set CiteSeerX~\cite{Wu2015,Wu2016,Patel2021}, for example, takes the approach of clustering references and publications, but there is no assessment of the citation network's completeness---i.e., what proportion of references of a paper can successfully be linked to the cited document. The more recently introduced data set S2ORC~\cite{Lo2020}---more specifically, it's \LaTeX\ subset---provides an investigation into the proportion of successfully matched references, but only achieves to successfully match 31.1\% of references. Improvements regarding citation network quality are presented in Chapters~\ref{chp:corpus} and \ref{chp:covgran}.
    \item \textbf{Anglocentrism} In the last years, there as been a growing awareness of non-English language content in various areas of NLP~\cite{Dabre2020,Yu2022,Ramesh2023}. However, in research concerned with scientific publications, as well as in available data sets covering scientific publications, there still is a major lack of coverage of non-English documents~\cite{Vera-Baceta2019,Liu2019,Moed2018,Moskaleva2019,MartinMartin2021}. As a consequence, research results are of limited validity. Improvements regarding the inclusion and analysis of non-English publications are presented in Chapter~\ref{chp:xling}.
    \item \textbf{Research Artifacts} To an increasing degree research is driven by curated data sets and algorithmic processing techniques such as machine learning methods and models (``research artifacts''). This development can, for example, be observed in the field of NLP, which has undergone a shift towards ``rapid discovery science'', characterized by a high consensus on research topics, methods and technologies~\cite{Jurgens2018}. Further signs of the growing importance of research artifacts are, for example, the launch of both Google Dataset Search\refurl{https://datasetsearch.research.google.com/}{2023-11-24} and Papers With Code\refurl{https://paperswithcode.com/}{2023-11-24} in 2018, as well as the gradual adoption of data citations~\cite{Kratz2015}.
% GDS 2018: https://doi.org/10.1038/d41586-018-06201-x
% PwC 2018: https://web.archive.org/web/20220513185917/https://www.reddit.com/r/MachineLearning/comments/8t0l40/p_papers_with_code_the_latest_machine_learning/
Despite these developments, efforts to include structured representations of research artifacts in scholarly data are limited. Some work in this direction exists, most notably SciERC~\cite{luan2018scierc} and SciREX~\cite{Jain2020scirex}, but it only covers a shallow representation of research artifacts. Improvements regarding a more fine-granular coverage of research artifacts are presented in Chapter~\ref{chp:params}.
\end{enumerate}

In addressing above limitations, we alleviate the state of scholarly data. This improvement is also reflected in the data quality dimensions introduced in Section~\ref{sec:intro-researchobj}, and will be tracked along the dissertation at the beginning of each chapter.

% per chapter: cit network, xling, params
% other: cleanliness/precision (but arXMLiv), automation (only compared to ORKG), ...

% others'
% - ORKG
% - OpenAlex(?)
% - Crossref(?)
% - CiteSeer
% - S2ORC

% The Open Research Knowledge Graph (ORKG)~\cite{orkg1,orkg2} provides information on over 28\,k publications, their contributions, research problems addressed etc. For its data, the ORKG is largely reliant on manual or semi-automated data entry.

% CiteSeerX~\cite{Wu2015,Wu2016,Patel2021}, generated from PDF files of various sources, over 10\,M documents, from various fields including medicine and biology, physics, mathematics, and computer science.

% S2ORC~\cite{Lo2020}, generated from PDF files of various sources, over 12\,M documents, from various fields including medicine and biology, physics, mathematics, and computer science.

% limitations
% - 

% USPs of presented work
% - 


%Measuring the Evolution of a Scientific Field through Citation Frames~~\cite{Jurgens2018} (usable here (or in HyperPIE chapter) for extra justification of focus on parameters of used artifacts)

% - - - - - - - - - - - - - - - - - - - - - - - - - - - -

% \begin{infobox-pub}
% \textbf{Publication} \fullcite{Saier2020}
% \end{infobox-pub}

% \begin{infobox-discussion}
% \textbf{Discussion} This text should show what a printed text will look like at this place. If you read this text, you will get no information. Really? Is there no information?
% \end{infobox-discussion}

% \begin{infobox-info}
% \textbf{Remark} This text should show what a printed text will look like at this place. If you read this text, you will get no information. Really? Is there no information?
% \end{infobox-info}

% \begin{infobox-progress}
%       \begin{tabular}{ccl}
%         \toprule
%         Crit.\tnote{a} & Res.\tnote{b} & Explanation \\
%         \midrule
%         \textbf{C1} & {\large\textbf{+}} & Representative coverage in physics, mathematics, CS \\
%         \textbf{C2} & $\circ$ & Primary focus on text content \\
%         \textbf{C3} & {\large\textbf{+}} & $>96$\% accuracy in reference matching \\
%         \textbf{C4} & {\large\textbf{+}} & Low noise due to using \LaTeX\ as data source \\
%         \textbf{C5} & {\large\textbf{+}} & Publications until end of most recent full year \\
%         \textbf{C6} & {\large\textbf{+}} & Provides MAG and arXiv IDs; DOIs in linked MAG \\
%         \textbf{C7} & $\circ$ & Not considered at this stage \\
%         \textbf{C8} & {\large\textbf{+}} & 42.6\% reference matching success rate \\
%         \textbf{C9} & {\large\textbf{+}} & Full-text included \\
%         \bottomrule
%       \end{tabular}
% \end{infobox-progress}

% - - - - - - - - - - - - - - - - - - - - - - - - - - - -

% \section{Research Questions}

% Research questions are provided as a guidance to the reader, giving a high-level perspective on the insights provided by the publications making up this dissertation.

% RQ "formulas":
% Q: "How can <goal> be achieved? A: "<proposed method>"
% Q: "How can <proposed method aspect> be leveraged to achieve <goal>? A: "<proposed method>"
% Q: "What's the nature of <analysis object>?" A: "<analysis result>

\section{Outline and Contributions}

The contributions made across the works tackling the challenges and limitations outlined in Sections \ref{sec:intro-challenges} and \ref{sec:intro-gap} represent the main part of this dissertation. Together with the subsequent and final chapter they make up the remainder of the document, which is structured as follows.

\begin{itemize}
    \item Chapter~\ref{chp:foundations} - \textbf{Foundations}
    \item Chapter~\ref{chp:corpus} - \textbf{Corpus}
    \item Chapter~\ref{chp:covgran} - \textbf{Reference Coverage and Granularity}
    \item Chapter~\ref{chp:xling} - \textbf{References Across Languages}
    \item Chapter~\ref{chp:params} - \textbf{References with Usage Parameters}
    \item Chapter~\ref{chp:conclusion} - \textbf{Conclusion}
\end{itemize}

In Chapter~\ref{chp:foundations}, Foundations, we introduce overarching and foundational concepts related to scholarly data as well as data mining and information extraction. The provided information is conducive to understanding (1)~decisions made in the system design and method development of the approaches discussed later on, and (2)~the quantification of the research goals and achieved results.

Chapters~\ref{chp:corpus} to \ref{chp:params} make up the main contributions of the work presented in this dissertation. Specifically, these are:

\textbf{Linked Document Scholarly Data Corpus Creation from \LaTeX} With \emph{unarXive} we present in Chapter~\ref{chp:corpus} a methodology for creating a large-scale corpus of linked, full-text documents from \LaTeX\ source files. At the time of publication it was the first corpus of linked publications with representative coverage in physics, mathematics, and computer science. By creating the corpus from \LaTeX\ source files, it is less noisy than related work created from PDFs, such as CiteSeerX~\cite{Wu2015}. The creation method furthermore includes a highly accurate reference matching procedure achieving a state-of-the-art matching success rate. The work achieves improvements across all five data quality dimensions.

\textbf{Inter-Reference Blocking and Fine-Granular Text Representation} Building upon \emph{unarXive}, we present in Chapter~\ref{chp:covgran} advancements in two areas. First, regarding the citation network, we develop a inter-reference blocking and matching method that significantly increases matched references as well as bibliographic couplings, and achieve a new state-of-the-art matching success rate. Second, we present an improved conversion method for \LaTeX\ source files leading to fine-granularly structured document representations. % Consider putting a sentences regarding the updated unarXive here, comparing it to S2ORC (mentioning that S2ORC (LaTeX) pipeline is based on unarXive)
In total, the work presented achieves data quality improvements in terms of relevance, timeliness, comparability, and completeness.

\textbf{Detection and Large-Scale Analysis of Cross-Lingual Citations} Using the \emph{unarXive} corpus, we present in Chapter~\ref{chp:xling} a method to reliably identify cross-lingual citations in English publications. Based on this, we conduct the so far largest analysis of this type of citation. Where previous studies of comparable setting only looked at hundreds of documents, our study includes over one million publications. Analysing cross-lingual citations' prevalence, usage, and impact, we identify trends over time as well as challenges. The work results in improvements in the citation network's relevance and comparability.

\textbf{Information Extraction for Hyperparameter Information} To further improve the granularity of the full-text representations in \emph{unarXive}, we develop in Chapter~\ref{chp:params} information extraction methods for research artifacts and their usage parameters. In doing so, we enable the study of parameter use and reporting patterns across time and scientific disciplines. The extracted information furthermore bears potential for use in automated reproduction. The developed methods achieve an improvement over strong baselines. Regarding data quality, the work represents improvements regarding the document representation in the dimensions relevance and comparability.

The dissertation concludes in Chapter~\ref{chp:conclusion} with an overarching discussion of the results attained, impact of the work so far, and an outlook.

\section{Overview of Publications}

The contributions in this dissertation have been published in peer-reviewed international conferences and journals. Table~\ref{tab:primarypublicationoverview} gives an overview of the publications and the chapters they make up. Venue ranks are taken from Core\refurl{http://portal.core.edu.au/conf-ranks/}{2023-10-12} in the case of conferences and from SJR\refurl{https://www.scimagojr.com/}{2023-10-12} in the case of journals.\footnote{The ranks shown are the rating for the respective publication year, or, if not available, the most up-to-date prior ranking. For workshops, the rank of the conference at which the workshop is hosted is shown.} For all publications in Table~\ref{tab:primarypublicationoverview} the author of this dissertation is the first and corresponding author. Detailed author contributions according to the Contributor Roles Taxonomy\refurl{https://credit.niso.org/}{2023-10-12} are listed at the end of the respective chapter.

\begin{table}[h]
\caption{Overview of publications reused in this dissertation.}
\label{tab:primarypublicationoverview}
  \centering
  % \begin{small}
  \begin{threeparttable}
  \begin{tabular}{crllllr}
    \toprule
    Chapter & Venue & Rank\tnote{a} & Type & Year & Length & Ref \\
    \midrule
    3 & Scientometrics & SJR Q1 & Journal & 2020 & Full & \cite{Saier2020} \\
    \arrayrulecolor{lightgrey}\cline{1-7}
    \multirow{2}{*}{4} & ULITE@JCDL & Core A* & Workshop & 2022 & Full & \cite{Saier2022ULITE} \\
    \ & JCDL & Core A* & Conference & 2023 & Short & \cite{Saier2023unarXive} \\
    \arrayrulecolor{lightgrey}\cline{1-7}
    \multirow{2}{*}{5} & ICADL & Core A & Conference & 2020 & Full & \cite{Saier2020xling} \\
    \ & IJDL & SJR Q2 & Journal & 2022 & Full & \cite{Saier2021} \\
    \arrayrulecolor{lightgrey}\cline{1-7}\arrayrulecolor{black}
    6 & ECIR & Core A & Conference & 2024 & Full & \cite{Saier2023hyperpie} \\
    \bottomrule
  \end{tabular}
  \begin{tablenotes}
    \item[a] Venue rank in publication year (or closest prior). For workshops, the rank of the hosting conference is shown.
  \end{tablenotes}
  \end{threeparttable}
  % \end{small}
\end{table}

% \begin{table}[h]
% \caption{Overview of publications reused in this dissertation.}
% \label{tab:primarypublicationoverview}
%   \centering
%   \begin{small}
%   \begin{threeparttable}
%   \begin{tabular}{cp{5cm}p{0.7cm}llllr}
%     \toprule
%     Chap. & Publication & Venue & Year & Type & Length & Rank\tnote{a,b} & Ref. \\
%     \midrule
%     3 & unarXive: A Large Scholarly Data Set with Publications’ Full-Text, Annotated In-Text Citations, and Links to Metadata & Scien\-tome\-trics & 2020 & Journal & Full & SJR Q1 & \cite{Saier2020} \\
%     \arrayrulecolor{lightgrey}\cline{1-8}
%     \multirow{2}{*}{4} & A Blocking-Based Approach to Enhance Large-Scale Reference Linking & JCDL & 2022 & Workshop & Full & Core A* & \cite{Saier2022ULITE} \\
%     \ & unarXive 2022: All arXiv Publications Pre-Processed for NLP, Including Structured Full-Text and Citation Network & JCDL & 2023 & Conf. & Short & Core A* & \cite{Saier2023unarXive} \\
%     \arrayrulecolor{lightgrey}\cline{1-8}
%     \multirow{2}{*}{5} & A Large-Scale Analysis of Cross-lingual Citations in English Papers & ICADL & 2020 & Conf. & Full & Core A & \cite{Saier2020xling} \\
%     \ & Cross-Lingual Citations in English Papers: A Large-Scale Analysis of Prevalence, Usage, and Impact & IJDL & 2022 & Journal & Full & SJR Q2 & \cite{Saier2021} \\
%     \arrayrulecolor{lightgrey}\cline{1-8}\arrayrulecolor{black}
%     6 & HyperPIE: Hyperparameter Information Extraction from Scientific Publications & ECIR & 2023 & Conf. & Full & Core A & \cite{Saier2023hyperpie} \\
%     \bottomrule
%   \end{tabular}
%   \begin{tablenotes}
%     \item[a] Venue rank (rating for the publication year, or the most up-to-date ranking if no ranking for publication year is available).
%     \item[b] For workshops, the rank of the conference at which the workshop is hosted is shown.
%   \end{tablenotes}
%   \end{threeparttable}
%   \end{small}
% \end{table}

Additional publications (co-)authored leading up to and during the research period which are not a direct part of this dissertation, but nevertheless informed the overall research trajectory, are listed in Table~\ref{tab:secondarypublicationoverview}.

\begin{table}[h]
  \caption{Overview of secondary publications not reused in this dissertation.}
  \label{tab:secondarypublicationoverview}
  \centering
  % \begin{small}
  \begin{threeparttable}
  \begin{tabular}{rlllclr}
    \hline
    Venue & Rank\tnote{a} & Type      & Year & Length & Pos.\tnote{b} & Ref. \\
    \hline
    BIR@ECIR  & Core A  & Workshop    & 2019 & Full   & 1 of 2 & \cite{Saier2019} \\
    ECIR      & Core A  & Conference  & 2020 & Full   & 1 of 3 & \cite{Saier2020a} \\
    SDP@NAACL & Core A  & Workshop    & 2021 & Short  & 3 of 4 & \cite{Krause2021} \\
    SDU@AAAI  & Core A* & Workshop    & 2022 & Full   & 2 of 3 & \cite{Shapiro2022} \\
    BIR@ECIR  & Core A  & Workshop    & 2022 & Full   & 4 of 5 & \cite{Faerber2022bir} \\
    JCDL      & Core A* & Conference  & 2022 & Full   & 3 of 3 & \cite{Nishioka2022} \\
    JCDL      & Core A* & Conference  & 2023 & Short  & 1 of 3 & \cite{Saier2023cocon} \\
    \hline
    \end{tabular}
    \begin{tablenotes}
      \item[a] Venue rank in publication year (or closest prior). For workshops, the rank of the hosting conference is shown.
      \item[b] Author position.
    \end{tablenotes}
    \end{threeparttable}
    % \end{small}
\end{table}

Especially \cite{Saier2019} and \cite{Saier2020a}, which constitute the results of the master's thesis preceding the doctoral research period, paved the way for this dissertation.
