\chapter{Introduction}
\label{chp:introduction}

% What do I want to say and convey here?
% - scientific publications are the ``footprint'' and ``medium of discourse'' of academic progress
% - structured representation

% establish the nature and role of scientific publications
Scientific publications are the \emph{discourse medium} and \emph{literary footprint} of academic progress. As such, they play a vital role in the everyday workings and advancement of academia.
% segue to the digital
Historically, this role manifested itself physically---through ink on paper. In time, digital methods for authoring %/composition?
and distribution enabled more efficient ways of dissemination.
Today, scientific publications are predominantly authored, distributed, consumed, and archived digitally~\cite{Lamers2018}. However, the form of today's digital publications still retains numerous and deep traces of its physical ancestry.

% Digital dissemination makes the transfer of new knowledge into the research community faster and cheaper. Digital archives enable search technology and analytics to operate on our \emph{literary footprint} of past and present academic progress. In this way, digitization facilitates both faster progress in science, \emph{and} technology helping scientists to keep up with the increase in speed. However, today's form of digital publications is far from optimal for powering such technology. In fact, the form of today's digital publications poses significant challenges for 

% While there lies enormous potential in a digital record of science, there remain significant challenges to realizing this potential. A key cause of these challenges is the historical baggage of today's digital publications. This dissertation is in pursuit of tackling these challenges.

% There lies enormous potential in a digital record of science. But realizing this potential

The historical baggage manifesting itself in the PDF files we read, share, and author, poses significant challenges to realizing the full potential of a digital record of science. While digital services in academia such as search and recommendation do exist, they are powered not by publications themselves, but rather by more structured, derivative representations of publications. The same holds for analyses of publications. The creation of such structured representations %/derivates?
is challenging and error prone, leading to a risk of subpar services and erroneous analyses. This dissertation represents and effort to tackle this challenge and alleviate the quality of structured representations of scientific publications.

% (random alliteration: structured surrogates of academic archives)

% - b/c of discrepancy between current form and what would be even better for digital dissemination and use (e.g. more structured), structured derivates of publications that enable digital services are of limited quality
% - historical baggage in part b/c still meant for human consumption
% - gap(?) between “pure” digital form and current form hinders more efficient use in digital services surrounding publications and academia

\section{Motivation}

% What do I want to say and convey here?
% - why do we have/need scholarly data?
% - in contrast to intro paragraphs above, make *necessity* of scholarly data for mitigating information overload clear
% - also make clear why there was realistic potential in approaching the challenge

In the following, we discuss the importance of structured representations of scientific publications---from hereon referred to as ``scholarly data'' for the sake of brevity%
\footnote{Note that in other contexts the term ``scholarly data'' can have a broader meaning than just ``structured representations of scientific publications''. For example, it can also include data on research institutions or funding bodies, without necessitating the context of a publication.}%
---, and based on that derive the motivation of the research project.

% * in the olden days there were polymaths
% * nowadays an expert can't humanly keep up with their field
% * → we need assistance
% * → my research in on enabling the creating of such assistance

% * since ever, humans have sought shortcuts
% * in decision making in science: h-index etc. (not sure if this fits b/c I don't specifically address such metrics)

The digitization of academic publishing has made the transfer of new knowledge into the research community faster, thereby enabling an acceleration of scientific progress. A second driver of acceleration is the increase in research spending across the world~\cite{CRS2022,OECD2023}.
This increase in scientific progress, while first and foremost a positive development, brings with it a growing challenge for researchers to keep up with the literature. This problem is referred to as ``information overload''~\cite{Landhuis2016}.
Fortunately, the digitization of academic publishing not only lead to %/facilitated
an increase in the rate at which research results are being published. It also marks the inception of scholarly data, and thereby enabled search technology and analytics to operate on large collections of digitally archived publications.
In this way, the existence of digital representations of publications also provides, to some degree, a remedy for information overload. Efficient search and recommendation services, for example, can aid researchers in navigating the deluge of publications they're faced with.
Similarly, decision processes in academia, such as the evaluation of institutions or researchers, is enabled by scholarly data through performance indicators. In this way, it provides a means for hiring and funding decisions.
In other words, scholarly data is a vital resource for decision making in academia on the individual as well as organisational level.

The quality of decisions made based on scholarly data, naturally, hinges on the quality of the scholarly data itself. Missing citation links in the data, for example, might cause researchers to overlook relevant related work, or a funding body under-evaluating an institution. Recalling that the creation of scholarly data is a challenging and error prone process, it stands to reason that efforts to improve scholarly data quality are a worthwhile endeavor. Based on these considerations, the overarching objective pursued in this dissertation is the development of methods for creating high-quality scholarly data.

% * not only is my research addressing the now pressing and increasing issue of an increasing rate of publication
% * it also tackles blind spots the have been left unaddressed for long (x-ling)

\section{Research Objective}\label{sec:intro-researchobj}

% What do I want to say and convey here?
% - make approached problem more concrete
%   - hand-wave-y in above:
%       ``[digital services in academia] are powered not by publications themselves,
%         but rather by more structured, derivative representations of publications''
%     -> publications authored by humans for humans -> scholarly data secondary/derivate
%     => concretization: derive structured representation from publications
%   - ``high-quality''
%     -> briefly touch upon what's laid out in foundation chapter
%     => concretization: high-quality = fitness for use
% - (maybe even narrow down to reference focus, maybe *even* more to LaTeX based)
% - give example

To define our research objective, we need to take a closer look at what ``creating high-quality scholarly data'' entails. As briefly laid out above, scholarly data is a derivate product of publications. This is due to the fact that, for the time being, scientific publications are written by humans for humans. Because the product of this process is not well suited for digital processing \emph{as is}, scholarly data is created as a derivate based on publications. To make this feasible on a large scale, the creation has to be automated.

Accordingly, we can define our research objective as follows.

\begin{infobox-objective}
\textbf{Research Objective}\\
Develop an automated process that takes as input scientific publications, and produces as output a high-quality derivate representation of the publications suitable for digital processing.
\end{infobox-objective}

This leaves the question of what ``high-quality'' and ``suitable for digital processing'' entail. We discuss this aspect in detail in Chapter~\ref{chp:foundations}. In short, data quality depends on the intended use and therefore, very generally speaking, means \emph{fitness for use}. Quantitatively it can be assessed along the following five dimensions~\cite{Herzog2007}.

\begin{infobox-progress}
      \textbf{Data Quality Dimensions}\\
       (1)~relevance, (2)~accuracy, (3)~timeliness, (4)~comparability, (5)~completeness
\end{infobox-progress}

A more specific and concrete definition of scholarly data quality along these dimensions can be grounded in considerations of how scholarly data is used. We elaborate on this in Section~\ref{sec:foundations-dataquality}.

\section{Challenges}

% What do I want to say and convey here?
% - (TODO: look at foundations part and see if challenges are laid out clearly already)

% big picture view on bridging the gap between historical baggage documents (print, scan, PDF, ...) and digital representation
% - large existing current effort
%       - document image dewarping\refurl{https://github.com/fh2019ustc/Awesome-Document-Image-Rectification}{2023-11-21}
%       - OCR
%       - PDF based scholarly data stuff

% - volume / growth rate (10^6 docs, 10^7 refs)
% - bridging visual medium and text information (formats etc., ref chap 2)
% - human made data (ambiguity, information sparsity)
% - reference open world something something
% - multi-lingual
% - specialized notation
% - 

Developing a process as described above is challenging for several reasons.

\begin{enumerate}
    \item \textbf{Data Volume} The value to be gained from scholarly data often increases with the number of publications covered. As a consequence, data sets are often very large (millions of documents). This leads to challenges in terms of processing efficiency, variability of data, and fault tolerance.
    \item \textbf{Unbounded Domain} A key characteristic of scientific publications is that they contain lots of references to other published works. This leads to the challenge of having to deal with an unbounded domain, because it is practically infeasible for a process as described in the previous section to have access to everything ever published or referenced.
    \item \textbf{Information Sparsity} Because the ``source material'' scholarly data is create from (publications) is created with human consumption in mind, various pieces of information necessary for understanding can be left out. This is due to the fact that readers can be assumed to possess relevant background knowledge. Following from this is the challenge of having to fill in background information in order to make scholarly data complete.
    \item \textbf{Semantic Ambiguity} Similar to information sparsity, the fact that the input data to be processed is natural language text, means the natural language processing (NLP) problem of ambiguity comes into play.
    \item \textbf{Multi-Linguality} While English currently is the de facto academic lingua franca~\cite{Montgomery2013}, science is a global endeavor meaning that scientific publications are written in various languages. Accordingly, the creation of scholarly data can entail the challenges that come with processing multi-lingual text.
    \item \textbf{Specialized Content} The fact that scientific publications address highly specialized topics, means that they are likely to contain both specialized terminology, as well as specialized notation. Both of these aspects result in further challenges in processing their natural language contents.
\end{enumerate}

Some of the aspects mentioned above are common for NLP tasks in general, such as semantic ambiguity. However, in their entirety, these challenges set the task apart from other areas, such as approaches concerned with news articles, which contain less specialized language, and websites, where the source material is more structured by nature. Rather close to above challenges is the processing of patents. However, patents also contain legal jargon, which is generally not the case for scientific publications.\footnote{The similarity between scientific publications and patents regarding the nature of their content, purpose, and requirements for automated processing, are likely the reason that some platforms, such as Google Scholar, handle both. (The search interface at \refurlinline{https://scholar.google.com/}{2023-11-22} includes a filter option ``include patents''.)}

% differences to patents: nature of the language technical and legal (as opposed to scientific)

\section{Research Gap}

This dissertation is not the first, and will certainly also not be the last research endeavor with the objective the develop methods for the creation of high-quality scholarly data. To position our work in relation to existing approaches, we highlight the research gaps addressed by this dissertation below. More detailed accounts regarding each area can be found in the respective chapters later on.

\begin{enumerate}
    \item \textbf{Citation Network} Several of the most prevalent use cases for scholarly data hinge on the interlinking of publications through citations. This includes a large amount of bibliometric analyses, scientometrics, as well as the study of citation networks in the general context of graphs (e.g. in graph neural network evaluations). Despite this, not much focus is put on the quality of citation networks in scholarly data. The much used data set CiteSeerX~\cite{Wu2015,Wu2016,Patel2021}, for example, takes the approach of clustering references and publications, but there is no assessment of the citation network's completeness---i.e., what proportion of references of a paper can successfully be linked to the cited document. The more recently introduced data set S2ORC~\cite{Lo2020}---more specifically, it's \LaTeX subset---provides an investigation into the proportion of successfully matched references, but only achieves to successfully match 31.1\% of references. Improvements regarding citation network quality are presented in Chapters~\ref{chp:corpus} and \ref{chp:covgran}.
    \item \textbf{Anglocentrism} In the past years, there as been a growing awareness of non-English language content in various areas of NLP~\cite{Dabre2020,Yu2022,Ramesh2023}. However, in research concerned with scientific publications, as well as in available data sets covering scientific publications, there still is a major lack of coverage of non-English documents~\cite{Vera-Baceta2019,Liu2019,Moed2018,Moskaleva2019,MartinMartin2021}. As a consequence, research results are of limited validity. Improvements regarding the inclusion and analysis of non-English publications are presented in Chapter~\ref{chp:xling}.
    \item \textbf{Research Artifacts} To an increasing degree research is driven by curated data sets and algorithmic processing techniques such as machine learning methods and models (``research artifacts''). This development can, for example, be observed in the field of NLP, which has undergone a shift towards ``rapid discovery science'', characterized by a high consensus on research topics, methods and technologies~\cite{Jurgens2018}. Further signs of the growing importance of research artifacts are, for example, the launch of both Google Dataset Search\refurl{https://datasetsearch.research.google.com/}{2023-11-24} and Papers With Code\refurl{https://paperswithcode.com/}{2023-11-24} in 2018, as well as the gradual adoption of data citations~\cite{Kratz2015}.
% GDS 2018: https://doi.org/10.1038/d41586-018-06201-x
% PwC 2018: https://web.archive.org/web/20220513185917/https://www.reddit.com/r/MachineLearning/comments/8t0l40/p_papers_with_code_the_latest_machine_learning/
Despite these developments, efforts to include structured representations of research artifacts in scholarly data are limited. Some work in this direction exists, most notably SciERC~\cite{luan2018scierc} and SciREX~\cite{Jain2020scirex}, but it only covers a shallow representation of research artifacts. Improvements regarding a more fine-granular coverage of research artifacts are presented in Chapter~\ref{chp:params}.
\end{enumerate}

In addressing above limitations, we alleviate the state of scholarly data. This improvement is also reflected in the data quality dimensions introduced in Section~\ref{sec:intro-researchobj}, and will be tracked along the dissertation at the beginning of each chapter.

% per chapter: cit network, xling, params
% other: cleanliness/precision (but arXMLiv), automation (only compared to ORKG), ...

% others'
% - ORKG
% - OpenAlex(?)
% - Crossref(?)
% - CiteSeer
% - S2ORC

% The Open Research Knowledge Graph (ORKG)~\cite{orkg1,orkg2} provides information on over 28\,k publications, their contributions, research problems addressed etc. For its data, the ORKG is largely reliant on manual or semi-automated data entry.

% CiteSeerX~\cite{Wu2015,Wu2016,Patel2021}, generated from PDF files of various sources, over 10\,M documents, from various fields including medicine and biology, physics, mathematics, and computer science.

% S2ORC~\cite{Lo2020}, generated from PDF files of various sources, over 12\,M documents, from various fields including medicine and biology, physics, mathematics, and computer science.

% limitations
% - 

% USPs of presented work
% - 


%Measuring the Evolution of a Scientific Field through Citation Frames~~\cite{Jurgens2018} (usable here (or in HyperPIE chapter) for extra justification of focus on parameters of used artifacts)

% - - - - - - - - - - - - - - - - - - - - - - - - - - - -

% \begin{infobox-pub}
% \textbf{Publication} \fullcite{Saier2020}
% \end{infobox-pub}

% \begin{infobox-discussion}
% \textbf{Discussion} This text should show what a printed text will look like at this place. If you read this text, you will get no information. Really? Is there no information?
% \end{infobox-discussion}

% \begin{infobox-info}
% \textbf{Remark} This text should show what a printed text will look like at this place. If you read this text, you will get no information. Really? Is there no information?
% \end{infobox-info}

% \begin{infobox-progress}
%       \begin{tabular}{ccl}
%         \toprule
%         Crit.\tnote{a} & Res.\tnote{b} & Explanation \\
%         \midrule
%         \textbf{C1} & {\large\textbf{+}} & Representative coverage in physics, mathematics, CS \\
%         \textbf{C2} & $\circ$ & Primary focus on text content \\
%         \textbf{C3} & {\large\textbf{+}} & $>96$\% accuracy in reference matching \\
%         \textbf{C4} & {\large\textbf{+}} & Low noise due to using \LaTeX\ as data source \\
%         \textbf{C5} & {\large\textbf{+}} & Publications until end of most recent full year \\
%         \textbf{C6} & {\large\textbf{+}} & Provides MAG and arXiv IDs; DOIs in linked MAG \\
%         \textbf{C7} & $\circ$ & Not considered at this stage \\
%         \textbf{C8} & {\large\textbf{+}} & 42.6\% reference matching success rate \\
%         \textbf{C9} & {\large\textbf{+}} & Full-text included \\
%         \bottomrule
%       \end{tabular}
% \end{infobox-progress}

% - - - - - - - - - - - - - - - - - - - - - - - - - - - -

% \section{Research Questions}

% Research questions are provided as a guidance to the reader, giving a high-level perspective on the insights provided by the publications making up this dissertation.

% RQ "formulas":
% Q: "How can <goal> be achieved? A: "<proposed method>"
% Q: "How can <proposed method aspect> be leveraged to achieve <goal>? A: "<proposed method>"
% Q: "What's the nature of <analysis object>?" A: "<analysis result>

%\section{Outline and Contributions}
\section{Contributions}

The work presented in this dissertation makes the following contributions.

\textbf{Linked Scholarly Data Corpus from \LaTeX} \Blindtext[1]

\textbf{Inter-Reference Blocking} \Blindtext[1]

\textbf{Fine-Granular Scholarly Data from \LaTeX} \Blindtext[1]

\textbf{Information Extraction for Hyperparameter Information} \Blindtext[1]

\section{Overview of Publications}

\begin{table}[tb]
\centering
  \caption{Overview of publications reused in this dissertation.}
  \label{tab:primarypublicationoverview}
  \begin{tabular}{cllllclr}
    \hline
    \ & \ & \ & \ & \ & Author & Venue & \ \\
    Chap. & Venue & Year & Type & Length & Position & Rating & Ref. \\
    \hline
    3 & Scientometrics & 2020 & Journal & Full & 1 of 2 & SJR Q1 & \cite{Saier2020} \\
    \arrayrulecolor{lightgrey}\cline{1-8}
    \multirow{2}{*}{4} & JCDL & 2022 & Workshop & Full & 1 of 3 & Core A* & \cite{Saier2022ULITE} \\
    \ & JCDL & 2023 & Conference & Short & 1 of 3 & Core A* & \cite{Saier2023unarXive} \\
    \arrayrulecolor{lightgrey}\cline{1-8}
    \multirow{2}{*}{5} & ICADL & 2020 & Conference & Full & 1 of 2 & Core A & \cite{Saier2020xling} \\
    \ & IJDL & 2022 & Journal & Full & 1 of 3 & SJR Q2 & \cite{Saier2021} \\
    \arrayrulecolor{lightgrey}\cline{1-8}\arrayrulecolor{black}
    6 & ECIR & 2023 & Conference & Full & 1 of 4 & Core A & \cite{Saier2023hyperpie} \\
    \hline
    \end{tabular}
\end{table}

The contributions in this dissertation have been published in peer-reviewed international conferences and journals. Table~\ref{tab:primarypublicationoverview} gives an overview of the publications and the chapters they make up. Venue ranks are taken from Core\refurl{http://portal.core.edu.au/conf-ranks/}{2023-10-12} in the case of conferences and from SJR\refurl{https://www.scimagojr.com/}{2023-10-12} in the case of journals.\footnote{The ranks shown are the rating for the respective publication year, or the most up-to-date ranking if the latter is not listed. For workshops, the rank of the conference at which the workshop is hosted is shown.} For each of the publications, detailed author contributions according to the Contributor Roles Taxonomy\refurl{https://credit.niso.org/}{2023-10-12} are listed at the end of the respective chapter.

\begin{table}[tb]
\centering
  \caption{Overview of secondary publications not reused in this dissertation.}
  \label{tab:secondarypublicationoverview}
  \begin{tabular}{llllclr}
    \hline
    \ & \ & \ & \ & Author & Venue & \ \\
    Venue & Year & Type & Length & Position & Rating & Ref. \\
    \hline
    ECIR & 2019 & Workshop & Full & 1 of 2 & Core A & \cite{Saier2019} \\
    ECIR & 2020 & Conference & Full & 1 of 3 & Core A & \cite{Saier2020a} \\
    NAACL & 2021 & Workshop & Short & 3 of 4 & Core A & \cite{Krause2021} \\
    AAAI & 2022 & Workshop & Full & 2 of 3 & Core A* & \cite{Shapiro2022} \\
    ECIR & 2022 & Workshop & Full & 4 of 5 & Core A & \cite{Faerber2022bir} \\
    JCDL & 2022 & Conference & Full & 3 of 3 & Core A* & \cite{Nishioka2022} \\
    JCDL & 2023 & Conference & Short & 1 of 3 & Core A* & \cite{Saier2023cocon} \\
    \hline
    \end{tabular}
\end{table}

Additional publications (co-)authored leading up to and during the research period which are not a direct part of this dissertation, but nevertheless informed the overall research trajectory, are listed in Table~\ref{tab:secondarypublicationoverview}. Especially \cite{Saier2019} and \cite{Krause2021}, which constitute the results of the master's thesis preceding the doctoral research period, paved the way for this dissertation.

\section{Outline}
\Blindtext[1]

% unarXive
% |  |  |
% |  |  v
% |  |  blocking
% |  v
% |  unarXive22
% v       |
% xling   v
% |      Hyperpie
% v
% xling+
