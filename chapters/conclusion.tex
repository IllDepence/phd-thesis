\chapter{Conclusion}
\label{chp:conclusion}

\section{Summary}

% Structured representations of scientific publications bear large potential for accelerated progress and well-founded strategic decisions in academia. Their use furthermore can mitigate the information overflow that scientists are faced with.
% Our current ``digital record of science'', however, is limited in various ways. This not only prevents faster progress, but also means decisions based on current scholarly data can be flawed and analysis results faulty.
%In pursuit of a remedy, this dissertation set out to alleviate the state of scholarly data. To achieve this, the following research objective was set.
This dissertation set out to alleviate the state of scholarly data. To achieve this, the following research objective was set.

\begin{infobox-objective}
\textbf{Research Objective}\\
Develop an automated process that takes as input scientific publications, and produces as output a high-quality derivative representation of the publications, suitable for digital processing.
\end{infobox-objective}

Criteria for high quality in the context of scholarly data were defined across the following five dimensions.%\footnote{See Table~\ref{tab:scholdataquali} in Chapter~\ref{chp:foundations} for the list of criteria.}

\begin{infobox-progress}
      \textbf{Data Quality Dimensions}\\
       (1)~relevance, (2)~accuracy, (3)~timeliness, (4)~comparability, (5)~completeness
\end{infobox-progress}

For each dimension, criteria were defined for scholarly data's key aspects of the citation network (CN) and structured document representations (SDR), as shown in Table~\ref{tab:scholdataquali-again}.

% Based on the way scholarly data is used, the criteria were derived for two focus  areas, the citation network (CN) and structured document representations (SDR), as shown in Table~\ref{tab:scholdataquali-again}. %(see Section~\ref{sec:foundations-dataquality}), 

\begin{table}[tb]
  \caption{Scholarly Data Quality Criteria}
  \label{tab:scholdataquali-again}
  \centering
  \begin{small}
    \begin{threeparttable}
      \begin{tabular}{llll}  % p{9.7cm}
        \toprule
        Dimension & Focus & \multicolumn{2}{l}{Specific Criterion and Short Description} \\
        \midrule
        \multirow{2}{*}{Relevance} & CN & $\mathbf{Rel_{CN}}$ & Representative coverage of publications in area of study \\
        \ & SDR & $\mathbf{Rel_{SDR}}$ & Inclusion of relevant content types (text, math, etc.) \\
        \arrayrulecolor{lightgrey}\hline\arrayrulecolor{black}
        \multirow{2}{*}{Accuracy} & CN & $\mathbf{Acc_{CN}}$ & Correctly linked references \\
        \ & SDR & $\mathbf{Acc_{SDR}}$ & Noise-free full-text content \\
        \arrayrulecolor{lightgrey}\hline\arrayrulecolor{black}
        \multirow{2}{*}{Timeliness} & \multirow{2}{*}{both} & \multirow{2}{*}{$\mathbf{Tim_{C/S}}$} & \multirow{2}{*}{Coverage of recent publications} \\
        \ & \ & \ \\
        \arrayrulecolor{lightgrey}\hline\arrayrulecolor{black}
        \multirow{2}{*}{Comparability} & CN & $\mathbf{Coy_{CN}}$ & Use of established doc. identifiers (DOI, PMID, etc.) \\
        \ & SDR & $\mathbf{Coy_{SDR}}$ & Fine-granular, specifically typed content representation \\
        \arrayrulecolor{lightgrey}\hline\arrayrulecolor{black}
        \multirow{2}{*}{Completeness} & CN & $\mathbf{Cos_{CN}}$ & All references in publications successfully linked \\
        \ & SDR & $\mathbf{Cos_{SDR}}$ & No sections or content missing (appendices, math, etc.) \\
        \bottomrule
      \end{tabular}
      % \begin{tablenotes}
      % \end{tablenotes}
    \end{threeparttable}
  \end{small}
\end{table}

To focus the efforts of improving scholarly data quality, we identified three areas in which current scholarly data particularly has limitations (see also Section \ref{sec:intro-gap}).

\begin{enumerate}
    \item \textbf{Citation Network}\\
          Lacking completeness of the network connecting publications through citations.
    \item \textbf{Anglocentrism}\\
          Lacking coverage of non-English publications in data used and analyzed.
    \item \textbf{Research Artifacts}\\
           Lack of structured representation of research artifacts mentioned in publications.
\end{enumerate}

In order to address these, four research tasks were defined.

\begin{rtlist}
    \item \textit{Base Methodology} - identify or establish a base methodology for generating a large-scale, high-quality scholarly data set, that is on par with or improving upon existing data sets.
    \item \textit{Citation Network Completeness} - develop a method to link literature references, that is able to link more references than are linked in existing data sets, while not compromising on link correctness or processing efficiency.
    \item \textit{Inclusion of Non-English Publications} - find and implement an approach to to include non-English publications into a large-scale, high-quality scholarly data set.
    \item \textit{Fine-gained Research Artifact Representations} - develop a method to extract fine-grained information on research artifacts from text in scientific publications.
\end{rtlist}

%To achieve improvements in these areas, the following steps were performed.
The four research tasks were accomplished as follows. % consider s/accomplish/carried out
In Chapter~\ref{chp:corpus} we developed a corpus creation method transforming publications' \LaTeX\ source files into a large-scale corpus of interlinked, annotated, full-text documents \rtmark{1\large\checkmark}. The presented method also includes a highly accurate reference matching procedure \rtmark{2}{\small(\checkmark)}. Applying our method on the complete set of all publications on arXiv.org, we created the data set \emph{unarXive}, which was used as a basis for all subsequent work. %``Corpus''
In Chapter~\ref{chp:covgran} we presented improvements regarding the citation network and the granularity of document representations. For the citation network, a blocking technique was developed that, applied on the set of references in a corpus, increases the number of matched references and bibliographic couplings. With an updated corpus creation method, the \emph{unarXive} data set achieved a more complete, state-of-the-art citation network \rtmark{2\large\checkmark}. The updated procedure furthermore enabled more fine-granular document representations, which in turn made the subsequent work in Chapter~\ref{chp:params} possible. %``Reference Coverage and Granularity''
In Chapter~\ref{chp:xling} we studied cross-lingual citations in the \emph{unarXive} corpus. For this, we developed a method to reliably identify this type of citation based on raw reference strings. In our study, which is the largest of its kind to date, we analysed cross-lingual citations' prevalence, usage, and impact \rtmark{3\large\checkmark}. %``References Across Languages''
Lastly, in Chapter~\ref{chp:params} we developed methods for extracting information about research artifacts and their usage parameters from publication full-texts. Applying our best performing method on \emph{unarXive}, we found differences in parameter reporting patterns across several disciplines \rtmark{4\large\checkmark}. %``References with Usage Parameters''

Through the accomplishment of the four research tasks, significant improvements across all quality dimensions and criteria were achieved, as summarized in the overview below.

\begin{infobox-progress}
      \textbf{Scholarly Data Quality Contributions - Overview}\vspace{0.5em}

      \begin{tabular}{llcccc}
        \toprule
        Quality Dimension & Criterion\hphantom{mmm}& \multicolumn{4}{c}{Contribution} \\
        \midrule
        \multirow{2}{*}{Relevance} & $\mathbf{Rel_{CN}}$ & {\large\textbf{+}} & = & {\large\textbf{+}} & $\circ$ \\
         & $\mathbf{Rel_{SDR}}$ & $\circ$ & {\large\textbf{+}} & $\circ$ & {\large\textbf{+}} \\
        \arrayrulecolor{lightgrey}\hline\arrayrulecolor{black}
        \multirow{2}{*}{Accuracy} & $\mathbf{Acc_{CN}}$ & {\large\textbf{+}} & = & $\circ$ & $\circ$ \\
         & $\mathbf{Acc_{SDR}}$ & {\large\textbf{+}} & = & $\circ$ & $\circ$ \\
        \arrayrulecolor{lightgrey}\hline\arrayrulecolor{black}
        Timeliness & $\mathbf{Tim_{C/S}}$ & {\large\textbf{+}} & {\large\textbf{+}} & $\circ$ & $\circ$ \\
        \arrayrulecolor{lightgrey}\hline\arrayrulecolor{black}
        \multirow{2}{*}{Comparability} & $\mathbf{Coy_{CN}}$ & {\large\textbf{+}} & {\large\textbf{+}} & {\large\textbf{+}} & $\circ$ \\
         & $\mathbf{Coy_{SDR}}$ & $\circ$ & {\large\textbf{+}} & $\circ$ & {\large\textbf{+}} \\
        \arrayrulecolor{lightgrey}\hline\arrayrulecolor{black}
        \multirow{2}{*}{Completeness} & $\mathbf{Cos_{CN}}$ & {\large\textbf{+}} & {\large\textbf{+}} & $\circ$ & $\circ$ \\
         & $\mathbf{Cos_{SDR}}$ & {\large\textbf{+}} & {\large\textbf{+}} & $\circ$ & $\circ$ \\
        \midrule
        \midrule
        \multicolumn{2}{r}{Chapter} & \ref{chp:corpus} & \ref{chp:covgran} & \ref{chp:xling} & \ref{chp:params} \\
        \multicolumn{2}{r}{Publication} & \cite{Saier2020} & \cite{Saier2022ULITE,Saier2023unarXive} & \cite{Saier2020xling,Saier2021} & \cite{Saier2023hyperpie} \\
        \bottomrule
      \end{tabular}

      \vspace{0.5em}
      \begin{footnotesize}
      \textbf{Legend}\\
      \textbf{+}: SOTA/improvement/etc. (see respective chapter)\\
      =: equal to previous\\
      $\circ$: not considered.
      \end{footnotesize}
\end{infobox-progress}

In summary, we successfully addressed three key areas of limitation of current scholarly data and achieved comprehensive improvements in data quality. All introduced methods operate automatcically and are demonstrably applicable to large-scale data. %Taking scientific publications as input, our methods generate structured representations.
Accordingly, we argue to have succeeded in developing an automated process producing high-quality derivative representation of scientific publications, and therefore accomplished our \textbf{{\color{objblue-box}\faCrosshairs}\,Research Objective \large\checkmark}

Naturally, advances uncover new challenges, and room for improvemet remains. In the following section, we therefore discuss the impact and limitations of our work, as well as prospective avenues for further improvement.

%Details regarding each of the contributions are given in the respective chapters. A discussion of the achieved improvements as well as their limitations can be found in the following section.

\section{Discussion}

% TODO: add some segue foo (bigger picture, broader view, etc.)
We discuss the contributions made in this dissertation from three different perspectives: (1)~the identified research gap, (2)~the five quality dimensions, and (3)~the research community.

% \begin{enumerate}
%     \item The identified research gap
%     \item The five quality dimensions
%     \item The research community
% \end{enumerate}

\subsection{Research Gaps}\label{sec:discussion-rgap}
We made significant progress in all three areas of the identified research gap.

\begin{enumerate}
% what
\item \textbf{Citation Network}\\
Achieving state-of-the-art citation network completeness on a large-scale, multi-discipline corpus,
% impact
means we enable analysis results more valid than previously possible, and the training of prediction models grounded more in reality than before.
% good enough?
That being said, our achieved completeness of 44.4\% means that missing citation links in scholarly data remain a problem.
% path forward
We see potential for future improvements in the development of sophisticated inter-reference blocking and matching methods, building upon our work in Chapter~\ref{chp:covgran}.
%
% what
\item \textbf{Anglocentrism}\\
Performing the largest study on citations of non-English publications to date,
% impact
we provide novel insight into a understudied phenomenon, and are able to highlight challenges for the integration of scholarly data across language borders.
% good enough? / path forward
Based on our findings, we see potential for improvements through better language support of platforms, and more widespread use of unique document identifiers. Another important aspect is the development of information extraction approaches applicable to non-English publications, which our work does not cover.
%
% what
\item \textbf{Research Artifacts}\\
With our task definition as well as model development and application for the extraction of hyperparameter information,
% impact
we enable the use and study of an important type of content in scientific publications.
% good enough?
Our model performance of 79\% $\text{F}_1$ for entity recognition and 39\% for relation extraction indicates remaining challenges particular regarding the latter.
% path forward
Based on our analysis, we can point to parameter entities as a particularly viable focus for achieving improvements in future endeavors.
\end{enumerate}

\subsection{Quality Dimensions}
Through addressing the identified research gap, our work achieves comprehensive improvements of data quality, as determined across five dimensions.

\begin{enumerate}
\item \textbf{Relevance}\\
Our improvements regarding relevance stem from two areas. (i)~We cover a large extent of documents with clear assignability to a subject of study, thereby facilitating, for example, representative coverage of an area of research. This improvement is by virtue of making use of arXiv as a data source. (ii)~We furthermore enable the extraction and structured representation of significant document contents, such as hyperparameter information. This improvement is independent of the specific data source used.
% “general relevance” ~= lots of data + clear assingability to subjects of study
\item \textbf{Accuracy}\\
Improvements we achieve in document representation accuracy are accomplished by harnessing a partially structured data source. In particular, we perform our work based on papers' \LaTeX\ sources. However, similar source types such as JATS XML and DOCX files bear the same potential. %, which presents an opportunity for future developments.
The citation network accuracy of >96\% that we achieve is already very high, with identified errors being edge cases such as follow-up publications with near identical titles. % mby some addition wrt to recall (CN completeness) trade-off?
\item \textbf{Timeliness}\\
Our improvements in terms of data timeliness are a result of us updating our corpus to include recent publications (e.g. up until the end of the most recent completed year). This level of timeliness is arguably sufficient for the study of and applications based on phenomena that don't change within the span of a year, such as citing behavior or writing conventions (e.g. how hyperparameters are reported). Furthermore, a data set with a fixed set of contents is beneficial for comparison of approaches on the same data. For some applications, however, it is desirable to have data on publications included right with their release. An example for this would be paper recommendation. In such cases a ``living corpus'' that is constantly updated is preferable. % consider stating that this is (technically) possible to realize for ppl if they use our method (begs the question though why we then don't provide a living unarXive + snapshots)
\item \textbf{Comparability}\\
We achieve improvements in comparability primarily based on (i)~determining documents' unique identifiers, and (ii)~providing fine-granular structure in our document content representations. (i)~Regarding document identifiers, DOIs are most established in academia, but a significant portion of publications without DOI exists (e.g. 
%about 14\% of PubMed articles in 2015~\cite{10.1007/s11192-016-2225-6}
measured in 2014 on Web of Science and Scopus at 12\% in life sciences, 15\% in physical \& health sciences, and 23\% in social sicences \& humanities~\cite{Gorraiz2016}).
By providing additional identifiers, we can cover part of those as well. (ii)~As for document content, the typed section and paragraph structure we provide in \textit{unarXive} represents natural semantic units on the intra-document level. On the level of sentences, a wide range of structures of interest can be conceived of. Our choice to focus on hyperparameter information is motivated by considerations of potential impact.
\item \textbf{Completeness}\\
Improvements we achieve in terms of data completeness stem from our reference matching---the results of of which we already discussed in Section~\ref{sec:discussion-rgap} above---, and our \LaTeX\ document conversion methodology. Regarding the latter, we are able to provide some document content in addition to the full-text---namely captions of tables and figures as well as mathematical notation. Tables and figures themselves would be a valuable addition, but require the development of additional extraction mechanisms and were not considered. % q: is it "there" if its contained but not in a structured way? i.e. in a PDF
\end{enumerate}

\subsection{Research Community}
Despite its recency, our work already made an impact on the research fields concerned with scholarly data and the study of publications. Below, we give a brief account of ideas and results from this dissertation permeating into and being used by the research community.

\begin{itemize}
    \item Use of \textbf{methodology}
    \begin{itemize}
        \item In~\cite{Lo2020} Lo et al.\ use our corpus creation methodology for creating the \LaTeX\ subset of their S2ORC data set.
        \item Chen et al.\ extend upon our reference matching procedure in~\cite{Chen2021} for the creation of their SciXGen data set.
    \end{itemize}
    \item Use for \textbf{model development and evaluation}
    \begin{itemize}
        \item Meyer et al.\ use our data for the development and evaluation of a citation recommendation model in~\cite{Citcom2021}. %~(\cite{Saier2019,HybridCite2020})
        \item In~\cite{Parisot2022} Parisot and Zavrel train a novel multi-objective representation learning technique for scientific document retrieval on our data.
        \item With Researcher2Vec Mochihashi present a method for researcher profile embeddings in~\cite{Mochihashi2023}, using our data to validate their approach.
        %\item Reference Linking~(\cite{Saier2022ULITE})
    \end{itemize}
    \item Use for \textbf{analyses}
    \begin{itemize}
        \item In~\cite{Veneri2022} Veneri et al.\ use our data to investigate how astronomers cite other research fields.
        \item Xue uses our data to analyse in~\cite{Xue2021} semantic shifts of the contexts in which works are cited. %~(\cite{Saier2020xling,Saier2021})
        \item Meng et al.\ use our data in~\cite{Meng2023} for an analysis of omitted citations of works that have become common knowledge --- so called ``obliteration by incorporation''.
    \end{itemize}
    % \item Use for \textbf{data set integration/extension}
    %\begin{itemize}  % TODO: add if Chen paper is ready in time
    %    \item Link Prediction~(\cite{Saier2023cocon})
    %    %\item NER+RE~(\cite{Saier2023hyperpie})
    %\end{itemize}
\end{itemize}

Comparing our work to existing efforts within the research community which strive to create high-quality scholarly data, we find that our work particularly stands out through the \emph{combination} of the following three aspects. (1)~Accurate, fine-granular document representations, (2)~a citation network, and (3)~applicability on a large scale due to being automated. This distinguishes our work from existing efforts as follows. S2ORC~\cite{Lo2020} predominantly uses PDF data and therefore does not provide the same level of granularity (e.g. mathematical notation) and is more prone to noise. arXMLiv~\cite{arXMLiv}, while providing accurate, fine-granular document representations, lacks a citation network. Lastly, the Open Research Knowledge Graph (ORKG)~\cite{orkg1,orkg2} relies on manual or only semi-automated adding of data, and is therefore limited in scale.

% TODO: consider discussing arXiv being a preprint server and the level of difference between preprints on arXiv and their published counterpart

% Note that in other contexts the term ``scholarly data'' can have a broader meaning than just ``structured representations of scientific publications''. For example, it can also include data on research institutions or funding bodies, without necessitating the context of a publication.

%Besides the work described above, there are also efforts of different nature striving towards the same goal. Our and aforementioned similar work seek to represent scientific publications in a broad way.
Our work, as well as the related work described above, seek to represent scientific publications in a broad way.
That is, multiple scientific disciplines and large time spans are covered, and the structured data reflects multiple aspects such as full-text, citation network, authors, etc. Another approach towards high-quality scholarly data are dedicated efforts in specific areas. An example of such an effort is the OpenCitations Index\refurl{https://opencitations.net/index}{2023-11-30}, focussing solely on citation data. Such an approach, however, necessitates the ability to combine multiple dedicated resources. For example, combining citation data with publication full-texts. This is only possible as far as unique persistent identifiers for all involved entities exist---e.g. DOIs for documents, ORCiDs for authors, and ROR IDs for affiliations~\cite{Meadows2019}. Although use of such identifiers is becoming more and more established~\cite{Gorraiz2016}, 
%\footnote{For example, arXiv.org began automatically assigning DOIs to all submissions in 2022, and Springer Nature trialed mandatory use of ORCiDs in 2018. See \refurlinline{https://blog.arxiv.org/2022/02/17/new-arxiv-articles-are-now-automatically-assigned-dois/}{2023-11-30} and \refurlinline{https://info.orcid.org/orcid-mandate-trial-at-springer-nature/}{2023-11-30}.}
gaps in their coverage mean that, for the moment, a combination of dedicated resources is only of limited use~\cite{Youtie2017,Haak2018}.

To briefly recap, we discussed our contributions and impact (1)~in terms of the addressed research gap, (2)~across the five data quality dimensions, and (3)~in relation to the research community. Overall, our work constitutes a range of measurable and demonstrated advancements, and has furthermore been taken up by the research community.

% shown the benefits of using a partially structured data source (\LaTeX, JATS XML, DOCX) --- q: is this really a core thing that warrants mentioning in such a prominent position here?

\section{Outlook}

We conclude with a brief look at viable extensions of our work, as well as potential future developments in scientific publishing and what they would mean for the presented work.

\subsection{Extensions of Our Work}

% extension to more input formats
\paragraph{Extension to Other Input Formats}
Our work takes publications' \LaTeX\ source files from arXiv.org as the starting point. Because \LaTeX\ provides a certain level of explicit document structure and semantic information, a natural extension would be to replicate our work on the likewise structured JATS XML publications of the PubMed Central Open Access Subset. This would widen the scope of the results attained, namely by adding life sciences to the already covered disciplines of physics, mathematics, and computer science. In disciplines other than the aforementioned, however, only PDFs are available in large quantities given the current state of scientific publishing. An extension to PDF input would likely come with challenges regarding structured document representations. However, the work we presented for the focus areas \emph{citation network}, \emph{non-English content}, and \emph{research artifacts}---see Chapters~\ref{chp:covgran}, \ref{chp:xling} and \ref{chp:params} respectively---is not reliant on \LaTeX\ as a starting point. This means, given methods for information extraction from PDFs producing output equal to our intermediate results from \LaTeX, extending our work to PDF based document collections is unlikely to pose difficulties.

\paragraph{Reference Parsing and Matching}
% - recall eval problem (boundless domain)
% - improves w/ continued adaption of DOI use (+DOI aware (+embedded link aware as ours) linking method)
%
% - better ref str parsing (DL, mention igor ppr) + preprocessing (embedded link aware as ours, etc.)
% - better clustering methods
% - increased DOI usage
We achieve state-of-the-art citation network completeness, but the amount of missing citation links in scholarly data remains an issue. Regarding future development, we see three key elements playing a role. First, the parsing of reference strings in order to extract structured information (title, authors, etc.) bears potential for improvement using synthetic training data~\cite{Shapiro2022}. Second, based on our work on reference clustering presented in Chapter~\ref{chp:covgran}, the development and application of novel clustering approaches is promising. Third, a continuation of the trend that DOIs usage is becoming more and more established~\cite{Gorraiz2016} can be expected to simplify the underlying challenge itself, at least regarding future publications.

\paragraph{Integration of Non-English Publication Repositories}
We studied references \emph{to non-English publications} in the English full-text documents in our corpus. More extensive follow-up studies could be made possible by integrating large repositories of non-English publications, such as the Japanese J-STAGE\refurl{https://www.jstage.jst.go.jp/}{2024-02-07} containing over 5 million open access articles. This would enable, for example, studying the ``reverse'' phenomenon of what we examined and analyse references \emph{from non-English} publications. Furthermore, the resulting large-scale multilingual full-text corpus would be a valuable resource for the development and evaluation of information extraction models not limited to English, thereby further counteracting Anglocentrism in scholarly data related research.

\paragraph{Utilization of Hyperparameter Information}
We developed models for the extraction of hyperparameter information from papers' full-text. To demonstrate their applicability on large-scale data, we perform an exemplary analysis of differences in hyperparameter reporting patterns across disciplines. Beyond this exemplary use, the extracted information bears potential for powering faceted academic search and recommendation systems, as well as the development of approaches to automated reproduction. However, because the performance of our models is still limited, especially in terms of relations extraction when parameter type entities are involved, we see further efforts towards model improvement as a priority.

%\vspace{1em}[Insert visionary paragraph; ``where the journey goes'' considering the above (more multi-discipline, multi-lingual, fine-granular structured information on artifacts etc.). Paint a picture of a possible future.]

\subsection{Future External Developments}

\paragraph{LLMs}
Regarding information extraction methodologies, a continuation of the recent advances in LLM technology could become a key factor in bridging the gap between our by-human for-human publications, and machine-readable scholarly data.
This is because, even though LLM performance is not on par with dedicated models yet~\cite{Yang2023}, the wide-ranging information available to them could allow filling in the assumed background knowledge that is necessary for understanding, but not explicitly mentioned in, scientific publications.
However, particular challenge with the application of LLMs for the creation of scholarly data is scaling approaches to large scale applications.

% the future of input formats
\paragraph{Tagged PDFs}
Looking beyond the current state of scholarly data, where it is necessary to apply information extraction methods to retroactively determine document structure and semantic information, future developments concerning ``tagged PDFs''\refurl{https://taggedpdf.com/}{2023-11-30} could simplify the creation of high-quality scholarly data. Widespread adoption of encouragement or requirements for semantically tagging PDFs could either be driven by efforts to improve the accessibility of scientific publications, or by the fact that it would facility data mining. In STEM fields, a prerequisite for such a developments would be that the \LaTeX\ Project's plan to support semantic annotation natively succeeds~\cite{Mittelbach2020,Mittelbach2023}.

% the future of publishing
\paragraph{What Constitutes a Publication}
Considering future developments of the landscape of scientific publications, changes to the status quo of papers being the primary unit of publication would accordingly bring changes to the nature of scholarly data. For example, establishment of micropublications~\cite{Raciti2018} and further adoption of data citations~\cite{Kratz2015} could bring new requirements and opportunities to scholarly data both in terms of data modeling as well as information extraction methods.

\vspace{1em}[Insert concluding words]
